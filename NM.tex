3. Experiment 1
3.1 Goals
Experiment 1 aims at using the simulation paradigm to investigate the specific influences of the various sound sources constituting urban soundscapes on the perceived pleasantness. For that, two first experiments are planned (Figure 3): • experiment 1.a (simulation): during this experiment, participants have to create urban sound environments, using the simulation tool Simscene (see sect. 2). Each of them creates two environments: one ideal / pleasant and the other one, non ideal / unpleasant. • experiment 2.a (evaluation): actually, after the simulation phase, we only have a binary information on the emotional properties of the respective scenes: ideal (i) and non ideal (ni). This second experimental step aims at investigating our knowledge on pleasantness. For that, a second goup of participants are asked to evaluate the pleasantness of each simulated scene, on a semantic scale. This evaluation protocol has two goals: 1. to evaluate the respective influence on the pleasantness of the various sources composing the scenes (i or ni) 2. to detect the presence of outliers or ambiguous samples. For the remainder of the study, the defined hedonic properties (i and ni) are used as ground truth. Then, we must have to be sure that no ambiguity exists between extreme cases of i and ni scenes; i.e that the lower i-scene is really above the upper ni-scene, in terms of pleasantness rating.
Our analysis is based on the data collected by these two experiments (1.a, 1.b)
[FIGURE 3] Figure 3: experimental protocol of the simulation experiment (1.a) and the pleasantness evaluation experiment (1.b)
3.2 Experiment 1.a
Procedure The participants have to simulate two urban sound environments of 1 minute each. They have to follow the instructions below: • 1st simulation: create a plausible urban soundscape which is ideal, according to you (where you would like to live); • 2nd simulation: create a plausible urban soundscape which is non ideal, according to you (where you would not like to live);
All the participants start by working on the ideal environment; they read the second set of instruction at the end of the first experiment. Participants are completely free of their choice concerning sounds and synthesis parameters. They must nevertheless respect the two following constraints : • the listening point of view is the one of a fixed listener; • the soundscape must be realistic, i.e. physically plausible. For instance, the participant can insert ten dogs in the soundscape but he/she can’t insert one dog barking every 10 milliseconds. These constraints are notified in the instructions; no control is done a priori in the simulation user interface
Each simulation process contains two parts : 1. composition of the simulation: this step is split in three steps • select the class of sounds • give a name to the selected class of sounds • set the parameters of the tracks (see section 2.2) related to the selected class of sounds. 2. production of a free verbalization of the composed soundscape
In addition, once the two sound scenes have been realized, participants are invited to • point out the sound sources that were missing for the composition • give a comment about the ergonomics of the simulation environment • give a comment about the ergonomics of the selection tool
Before starting the first simulation, a 20-minute tutorial is given to the participants in order to familiarize them with the simulation environment and the sound database. The experiment is planned to last about two hours and a half, including breaks that could be taken by the participants.
Apparatus All the participants do the experiment on similar computers. The audio files are played in diotic conditions by headphones. During the tutorial, participants are asked to adjust the sound level in order to be comfortable; they can’t modify it in the following of the experiment. All the participants do the experiment simultaneously. They are equally split in three identical quiet rooms. They can’t talk together during the experiment. Three experimenters (one in each room) are present during the whole duration of the experiment in order to check that everything goes well and possibly to answer questions.
Participants 44 students (14 females - mean age 21.6, SD = 2.0) from Ecole Centrale de Nantes took part to the experiment. They are all living in Nantes downtown since 2 years or more. Among the 44 participants, 40 succeeded in doing the experiment, producing in the end, 80 simulated sound scenes (40 ideal scenes, 40 non ideal scenes). 4 participants were excluded from the process for not having respect or understand the instructions, or for having exceed the allowed time.
3.3 Experiment 1.b
Procedure Due to temporal constraints, participants only assess 30 seconds of the initial 1-minute simulated scenes composed in Exp. 1.a (from sec. 15 to sec. 45). The assessment is done in a 7-point Likert scale going from -3 (non ideal / unpleasant) to +3 (ideal / pleasant). Before evaluating a scene, participants must listen to the first 2à seconds of the scene. After the evaluation, they are free to switch to the next scene. For each participant, sound scenes are played in a random order. The first 10 scenes allow the participants to calibrate their marks; they imperatively gather 5 ideal scenes and 5 non ideal scenes. These first 10 scenes are played back again at the end of the experiment and the corresponding evaluations are the ones that are only taken into account in the results. The experiment is planned to last 30 minutes. The participants don’t know anything beforehand about the nature of the sound scenes.
Apparatus All the participants do the experiment on similar computers. The audio files are played in diotic conditions by semi-open headphones (Beyerdynamic DT 990 Pro). All the sound scenes have been re-composed on the basis of the scores obtained in the simulation experiment (Exp. 1.a). The output sound level is the same for all the participants. All the participants do the experiment simultaneously. They can’t talk together during the experiment. An experimenter is present during the whole duration of the experiment in order to check that everything goes well and possibly to answer questions.
Participants 10 students (2 females - mean age 23.1, SD = 1.8) from Ecole Centrale de Nantes took part to the experiment. They are all living in Nantes since 2 years or more. None of them took part to the previous simulation experiment (Exp. 1.a). All the participants succeeded in doing the experiment.
3.4 Data and analysis methods
A set of features is attached to each sound scene. The analysis is done on the basis of these features. A summary of these features (and the corresponding acronyms) is presented in Table I. In order to stay coherent with the evaluation experiment 1.b, features are not computed in the whole duration of the sequences but only on their 30-second reduced version (see Section 3.3). For each sound scene, three types of features are considered : • perceptual: the perceived pleasantness of the composed scene, assessed on a 7-point Likert scale. $\mathcal{A}_{scene}$ is the mean pleasantness for one scene, as the average of the marks of all the participants. In the same idea, $\mathcal{A}_{subject}$ is the mean pleasantness for each participant, as the average of all the marks of each participant. Given the low volume of participants in Exp. 1.b, we decide not to normalize the values of pleasantness marks. • semantic: boolean vector S = (x1, x2, …, xn) that indicates the class of sounds involved in the scene. Each point x of this vector corresponds to a specifi class of sounds: x = 1 if the class is present in the scene, and x = 0 otherwise. The vector dimension (n) depends on the level of abstraction that is considered. For instance, for the abstraction level 1, including 44 classes of sounds, n = 44. • structural: related to sound level. To figure out the sound level, we got inspired from the $L_{Aeq}$ feature. In our case, it is a scalar computed from the signal (in Volt and not in Pascal), and converted in deciBels, with a reference of 1 Volt. The level is obtained by computing every second the quadratic mean of the signal and by averaging over the total duration of the scene. An A-filtering module is also processed before the quadratic means are computed. We note L, $L(E)$ and $L(T)$ the computed levels by taking into account respectively the whole set of samples, only the set of event samples and only the set of texture samples.
In order to evaluate the specific impact of the various sound sources on the perceived pleasantness, we put the data to the five following tests of significativity: • check of the pleasantness of the simulated sound scene: to check that the emotional difference produced by the i- and ni- scenes is also present in terms of perceived pleasantness, we look at the existence of differences between $\mathcal{A}_{scene}$ and $\mathcal{A}_{subject}$ with regards to the two types of scene. the significativity is evaluated by a Student test on two independant populations for $\mathcal{A}_{scene}$ and by a Student test on two paired populations for $\mathcal{A}_{subject}$ ; • analysis of the structural features: in order to evaluate wether the emotional difference forced to the i- and ni- scenes has a significative influence – i.e., if significative differences exist between structural features and perceived pleasantness –, we measure this significativity with a Student test on two populations; • study of the influence of the structural features on the perceived pleasantness: in order to evaluate a possible impact of the structural features on the perceived pleasantness, we look at linear correlations between these features and $\mathcal{A}_{scene}$. For that, we use the Pearson correlation coefficient, on the basis of the standard methodology used in multidimensional studies; • analysis of the semantic features: in order to determine if the forced emotional difference has an influence on the scenes composition in terms of sound sources, or if specific souns classes are more frequently used to simulate a given environment (i or ni), we apply a V-test. This test is done at every level of abstraction, and separately, for texture and event classes. For each class j, and each environment type k (k = {i, ni}), the V-test variable Vjk is computed as follows:
[EQUATION]
where c is the amount of classes, ck is the amount of classes for a type of environment k, cj the amount of j-classes, and Cjk the amount of j-classes used for an environment k. The V-test tests the null hypothesis that the ratio cjk / c is not significatively different from the ratio cjk / ck. For a given environment k and class j, if the hypothesis is rejected, the class j can then be considered typical with regards to the environment k. The typical classes are called sound markers. • study of the representation spaces induced by the semantic features: in order to determine if a representation only based on the presence / absence of sound sources allows to split the two types of environment, we investigate the space induced by the semantic features S. S is a boolean vector and the distance between two scenes is computed with the Hamming distance. Considering two n-dimension vectors S1 = (x1,1, x1,2, …, x1,n) and S2 = (x2,1, x2,2, …, x2,n) where x = {0,1}, the Hamming distance dham measures the proportion of coordinates that differ between two vectors, as follows:
[EQUATION]
where ✇ designate the exclusive-or operator. The more the two scenes are similar, the closer they are. The use of Hamming distance allows to take into account equally the present and absent classes. For measuring the intrinsic ability of the space to split the i- and ni- scene, we use a ranking metric named k- precision ($P@k$) . The $P@k$ computes the precision obtained after k items have been found. Formally, for each si scene, we compute the ratio between the number of sj scenes taken among the k nearest neighbors of si and sharing the same label than si with regards to the k items to be found. the $P@k$ is then the mean of this ratio along all the items; • influence of the sound markers on the perceived pleasantness: in order to assess the specific contributions of some sound sources, we again estimate the possible impact of the structural features on the perceived pleasantness, but this time, by only taking into account the sound markers for the computation of these features.
Except for the V-test, all the statistical test of significativity are done with a critical threshold ⍺ = 0.05. For the V-test, considering that a great number of classes is tested, a Bonferroni correction is applied. For the p-value, when p > 0.05, the value is mentioned. When 0.01 < p < 0.05, we only mention p < 0.05, otherwise we mention p < 0.01.
3.5 Results I Cheking of the pleasantness of the synthesized scenes First, in order to ensure the coherence of the data, wr check that none of the ni- scenes gets a $\mathcal{A}_{scene}$ higher than one of a i- scene. Four ni- scenes don’t respect that rule: they are removed, together with their corresponding i- scenes. 36 i -scenes and 36 ni -scenes remain for analysis. Secondly, we want to be sure that participants really perceived a difference in terms of pleasantness between i- and ni -scenes. For that, we investigate the mean pleasantness score for each participant $\mathcal{A}_{subject}$, computed separately for each type of environment. It appears that the i- scenes were perceived significatively more pleasant (p < 0.01) than the ni- scenes.
Analysis of the structural features First, we focus on the sound level. Figures 4a, 4b, and 4c depict the distributions of levels L, $L(E)$, $L(T)$. There is a significative difference in terms of sound level between i- and ni -scenes (L: p < 0.01) with a standard deviation of -7 $dB$. This difference is either siginificant for events ($L(E)$: p < 0.01), STD: -7 $dB$) than on textures ($L(T)$: p < 0.01), STD: -6 $dB$). As expected, we verify that the sound sources sound level is indeed a pleasantness indicator, the ni -scenes tending to be louder - what also comes out from a large number of related works. We also notice that this difference of sound level is equally true for events or textures.
[FIGURE 4] Figure 4. Distributions of the structural features L (a, d), $L(E)$ (B, e) and $L(T)$ (c, f) with regards to the type of scene (a, b, c) and the perceived pleasantness $\mathcal{A}_{scene}$ resulting from experiment 1.b (d, e, f)
It appears that the biggest influence on the global sound level comes from the events, the gap between L and $L(E)$ being only 1 $dB$ for i- and ni- scenes. This observation is in agreement with the results obtained by Kuwano et al. [37]. During their experiment, the authors ask to their participants to assess a set of soundscapes at a global level and then to do the same judgement at the moments when each of them detect a sound source. The study shows that there is no significative difference between global and averaged instantaneous judgements. In our case, the result can be interpreted as if the participants had unconsciously integrated this perceptual reality when composing the scenes, by assigning the global sound level to well identified short sounds, i. e. the events.
Finally, we notice that the level alone is not enough to differentiate the different types of environment. In fact, 20% of the i- scenes hast got a sound level higher than the nominal level of the ni- scenes, while there is no overlap when considering the perceived pleasantness $\mathcal{A}_{scene}$.
Influence of the structural features on the perceived pleasantness In this section, we analyse the deep relationships that could exist between structural features and perceived pleasantness. Contrary to the previous section, we don’t consider the emotional property of a scene on a binary mode (i vs. ni): here, we consider the mean pleasantness $\mathcal{A}_{scene}$ as a perceptual feature. The aim is to investigate the level of correlation between structural features and $\mathcal{A}_{scene}$. The linear correlation coefficients computed between $\mathcal{A}_{scene}$ and L, $L(E)$, and $L(T)$ are presented in Table II. Relationships between $\mathcal{A}_{scene}$ and the structural features are depicted in Figure 4d, 4e, and 4f.
Concerning L, we can observe a strong negative correlation (r = 0.77, p <0.01) avec $\mathcal{A}_{scene}$, indicating that the higher the sound level is, the more unpleasant the scene is perceived. Nevertheless, Figure 4d suggests that this relationship doesn’t occurr in the same way for i- and ni- scenes. In fact, the correlation between L and $\mathcal{A}_{scene}$ is high for ni- scenes (r = -0.78, p <0.01), but is quasi null for i- scenes. When considering the whole set of scenes, this result can be explained by the fact the i- scenes tends to be softer than the ni- scenes, deluding that the negative correlation observed for the ni- scenes is extended.
We can conclude that L: • allows to differentiate between i- and ni- scenes, • allows a fine characterization of the perceived pleasantness for ni- scenes, • is not a relevant feature for the perceived pleasantness for a priori pleasant soundscapes (i- scene)
The same report can be done concerning $L(E)$ (cf. Figure 4e). For $L(T)$ (cf. Figure 4f), the moderate correlation observed for the whole set of scenes disappears when separate scenes are considered (i- scenes, r = -0.33, p = 0.05; ni- scenes, r = -0.00, p = 0.99). One can suppose that the negative correlation coming from the whole is an artefact due to the level difference between the two types of scenes (i- scenes tend to be softer tant ni - scenes). Thus, the sound events keep a relative ability to predict the pleasantness of the ni- scenes, but the level of the textures doesn’t bring a lot of informations whatever the type of environment is.
To sum up, for an unpleasant environment, sound levels - especially those of the events - negatively influence the perceived pleasantness. On the contrary, for a pleasant environment, none of the structural features considered in the study seem to influence the perceived pleasantness. Those first outcomes could show that it exists two modes of perception depending on the nature of the environment (i- or ni-), and each involving independent features. The fact that L is not able to characterize the pleasantness of the i- scenes can lead us to think that all the sound sources don’t equally contribute to the perception of pleasantness, but that only the level of some of them can influence this percept. In order to go deeper in that direction, in the next section, we analyse these scenes on a semantic point of view, i.e. we take an interest in the nature of the sources they are made of.
[TABLE II] Table II. Linear correlation coefficients computed between mean perceived pleasantness (epx. 1.b) and structural features.
Analysis of the semantic features We analyse the composition of the scenes by counting the number of participants who used a given class of sounds to simulate the environment. Results are shown on Figure 5a for the events, and on Figure 5b for the textures. For sake of clarity, we chose a transitional level of abstraction between level 0 and 1, named 0+, to represent the classes. We observe a significant difference between i- and ni- scenes for the choise of classes. The distribution of the classes is very similar to to the one obtained in a related work on ideal urban soundscapes [5]: classes involving human presence and nature are prevailing in the i- scenes, and on the opposite, classes involving mechanical sounds and/or public works are prevailing in the ni- scenes. These results confirm a previously observed fact: the semantic nature of the sound sources play an important role in the assessment of the environment [23, 6] Nevertheless, we notice some differences with [5]: Guastavino’s results show that sounds of public transportation are specific of ideal urban soundscapes. The authors interpret this by the fact that the perception of pleasantness is, among other things, due to socio-cultural factors. In our representation of the world, sounds of public transportation are positively connoted and tend to be more accepted than sounds of personal vehicles. To a certain extent, our results are in contradiction with this assumption. In fact, Figure 5a shows public transportation classes (bus and train - see Figure 5c) have been used by the participants for i- scenes (28%) and ni - scenes (42%). the results don’t re-evaluate the fact that sounds of public transportation are well accepted: 25% of the participants have used the bus class for the i- scenes, that is comparable to the bicycle class and much higher than all the personal vehicles classes. This being, public transportation classes are also strongly present in the ni- scenes, for instance more than light vehicle or trucks classes. On the basis of our results, the public transportation class can’t be considered as typical of an ideal urban soundscape.
[FIGURE 5] Figure 5. Proportion of synthesized scenes (i or ni) involving a specific class of sounds: (a) event classes at an abstraction level 0+, (b) texture classes at an abstraction level 0, (c) event sub-classes at an abstraction level 1 belonging to traffic and public transportation classes of the abstraction level 0.
This difference can be explained by the nature of the experimental protocol used in the two studies. As in our case, Guastavino asks the participants for describing an environment; but in that case, they work from their memories whereas, in our case, participants do that task using sound samples. The fact that participants in our experiment are faced to the acoustic reality of the sounds for composing the environment may have decreased the socio-cultural impact. Other works using sounds as stimuli have shown that the bus class can have a negative influence on the assessment of the environment [8].

///

Sound markers We highlight that, on a qualitative point of view, the composition of the scenes in terms of sound sources differs regarding the type of environment (i or ni). We’re now trying to to investigate if some of the sound classes are specific to a given environment. For that, we use the V-test (see section 3.4) and consider separately each abstraction level. Results are presented in Table III.
[TABLE III] Table III. Event and texture classes identified as sound markers. In each cell, markers are ranked in the decreasing order of V value
Regarding the sound events, 9 markers are identified at all the abstraction levels. As Figure 5 could let it predict, classes related to human presence (male footsteps on concrete, bicycle ring) are i- scenes markers; we also notice the bell class as an i- scenes marker. This latter result may be due to the socio-cultural background of the participants who are mostly european citizens. In fact, according to Schafer, a sound that is identified by a person as being an element of his/her environment, is well accepted. Sound markers of ni- scenes are classes related to construction site (public works), or suggesting a strong traffic (horn, siren). Regarding the textures, 5 markers are identified. For the i- scenes, they are classes related to passive or quiet ambiances (courtyard, park). for the ni- scenes, as for the events, they are classes related to construction site (public work, construction vehicle), together with a class related to traffic (crossroad). Although the whode identified markers are intuitive, none of the event classes related to the noise of the motor vehicles is a marker, except for the texture class crossroad. To simulate an unpleasant traffic, participants chose the classes horn or siren. One can suppose that isolated motor vehicle sounds are understood as taking fully part of the urban environment, and thus are not especially linked to an unpleasant soundscape.
Representation space induced by semantic features In this section, we evaluate the ability of a semantic representation to split the two types of environment. For that, we compute a rank 5-precision (p@5) on the space induced by the semantic features S, and for each abstraction level (see section 3.4). The vectors S are built by using all the classes (ET), only the event classes (E), only the texture classes (T), only the event classes corresponding to sound markers (Em), or only the event classes excluding sound markers (Ew/o,m). We don’t consider the texture classes corresponding to sound markers, these latter being not enough numerous. for the same reasons, we don’t consider the event classes corresponding to sound markers at an abstraction level 0. Results are shown on Figure 6. Concerning ET, the p@5 is 76% for the abstraction level 0, and stay above 86% from the abstraction level 1. These results confirm that it is possible to make a clear distinction between the two types of environment on the unique basis of presence / absence of sound classes. We also notice that the higher the abstraction level is, the more important is the ability to make this distinction. In other words, the more one is precise in the scene description, the more one is able to clearly differentiate between i- and ni- scenes. Considering E and T separately, ir appears: 1) that the p@5 obtained with E is similar to the one obtained with ET ; 2) that the p@5 obtained with T is systematically lower than the one obtained with E, by 10% or 15%. Those results indicate that the semantic information allowing to split the two environments is mainly contained in the events. Moreover, these results are in line with the work done in [20] showing that we analyse in a causal manner (i.e. by identifying the sources) the event scenes which are composed of several sound events (see section 2.1). Finally, it appears that the p@5 obtained with Em is equal – or above – to the ones obtained with E or ET, although a partial information is used in that case to describe the scenes. The dimension of the vectors S for Em is lower than the dimension of vector S for E, itself lower than the dimension of vector S obtained when all the classes are considered (ET). Moreover, in the case when the sound markers are not taken into account for the description (Ew/o,m), the results fall even going under those obtained with only the textures. This confirms that most of the semantic information allowing to differentiate between i- and ni- scenes is included in the markers. To sum up, we deduce the following points from this analysis:
[FIGURE 6] Figure 6. P@5 obtained by considering the dissimilarity matrix computed from the paired Hamming distances of the semantic features vectors. The vectors are built by using all the classes (ET), only the event classes (E), only the texture classes (T), only the event classes corresponding to sound markers (Em), or only the event classes excluding sound markers (Ew/o,m).
1. unlike what we outlined with the structural features, a semantic description of the scenes constitution in terms of presence / absence of sound sources, allows to differentiate the two types of environments (i or ni); 2. the semantic information is mainly contained in the event sound classes; 3. only a part of the event classes, i.e. the sound markers, are useful to differentiate the i- and ni- scenes.
Since we have extracted the typical classes of the i- and ni- scenes and verified that the distinction between them was dependant to the presence of these classes, we have now to investigate wether a structural description of the scenes only based on sound markers, allows to characterize the perceived pleasantness, better than a global structural description.
Influence of the sound markers on the perceived pleasantness We evaluate the correlations between $\mathcal{A}_{scene}$ and the structural features. In this section, the structural features are computed by taking into account of the sound markers previoulsy identified. We define Xm, the X feature computed by taking into account only the sound markers. On the opposite, we define Xb (b for bruit / noise), the X feature computed by taking into account all the sound classes, except the sound markers. When the feature characterize an i- scene (idem for a ni- scene), we consider for the computation only the markers identified for the i- scenes (or the ni- scenes); we named them, i- markers (or ni- markers). Results are shown in Table IV. Concerning the sound levels (see Figure 7a, 7d), the same trends are observed between Lm, $L(E)$m and $L(T)$m, on one hand, and L, $L(E)$ and $L(T)$, on the other hand. Considering all the classes or only the markers, it appears that: 1. it exists a significative difference between levels of i- and ni- scenes (Lm, $L(E)$m and $L(T)$m: p < 0.01); 2. the sound level of scenes is mainly related to the sound events, compared to the textures; 3. the sound level of events has an influence on the perception of pleasantness for ni- scenes, but not for i- scenes; 4. the sound level of textures doesn’t play any role in the perception of the pleasantness.
In conclusion, the level of ni- markers has a negative influence on the pleasantness for the ni- scenes. On the other hand, the level of i- markers doesn’t influence the perceived pleasantness for the i- scenes.
Considering the non markers classes (see Figure 7b, 7e), we can observe on the i- scenes results, a weak negative correlation for Lb (r = -0.52, p < 0.01) and $L(E)$b (r = -0.51, p < 0.01). It is the first time that an objective feature allows us to define the pleasantness of the pleasant environments. This leads us to conclude that the level of non-typical sound classes of a pleasant environment has a negative influence on the pleasantness.
Besides, whereas $L(T)$ didn’t show any significative correlation for ni- scenes, a strong negative correlation is observed for $L(T)$b (r = -0.73, p < 0.01). This indicates that the level of non-markers texture classes doesn’t influence the perceived pleasantness in the same way for i- and ni- scenes. Sound level seems to have a negative effect for the ni- scenes, and no significant effect for the i- scenes.
To end, we consider a last group of features, namely Lm - Lb, $L(E)$m - $L(E)$b, $L(T)$m - $L(T)$b (see Figures 7c and 7f). These features describe the difference between the markers level and those of the other sound classes. They express the saliency of the markers with regards to the sound mixture.
For the i- scenes, a moderate positive correlation is observed for Lm - Lb (r = 0.67, p < 0.01) and $L(E)$m - $L(E)$b (r = 0.66, p < 0.01). for the ni- scenes no correlation is observed. Thus, for the i- scenes, it is not the absolute markers level that is important, but their relative level with regards to the other sounds composing the scene. Then, we can induce a double perceptual mechanism for the ideal environments:
[TABLE IV] Table IV. Linear correlation coefficients computed between mean perceived pleasantness $\mathcal{A}_{scene}$ (Exp. 1.b) and structural features related to the presence of sound markers.
[FIGURE 7] Figure 7. Distribution of the relative sound levels structural features related to the presence of markers Lm (A, d), $L(E)$m (b, e) and $L(T)$m (c, f) with regards to the type of scenes (a, b, c) and the perceived pleasantness measured in Exp. 1.b (d, e, f).
• the higher the absolute level of sounds not being i- markers, the weaker the pleasantness is, • the higher the relative level of i- markers is, with regards to the other sounds, the higher the pleasantness is.
For the ni -scenes, the fact that we observe significative correlations for Lm and $L(E)$m and no correlation for Lm - Lb and $L(E)$m - $L(E)$b shows that this the absolute level that is important.
3.6 Discussions
From this analysis, we can outline the following points: • differentiate the i- and ni- scenes: the semantic features, together with the global structural features (L, $L(E)$, and $L(T)$) allow to differentiate between i- and ni- scenes. The semantic description seems to be more powerful; • events or textures: whatever semantic or structural features, events are mainly useful to differentiate the two types of events; textures bring a limited amount of informations; • pleasantness prediction: if we consider the correlations between structural features and pleasantness, it seems that the way to perceive the quality of a given environment depends on its nature (i or ni). It is not conceivable to consider a same set of features to predict the pleasantness of i- and ni- scenes in the same time: - for the ni- scenes, global levels (L and $L(E)$), or level of sound markers (Lm and $L(E)$m) have a negative influence on pleasantness. We can notice here taht taking into account the contribution of each the different sources of the scene doesn’t improve the prediction performance, wit regards to a global analysis of the environment. - for the i- scenes, on the contrary, the pleasantness prediction needs to study separately the sound markers characteristics and those of the other sounds. Thus, the markers level, relative to the noise ($L(E)$m - $L(E)$b and Lm - Lb) is positively correlated to the pleasantness, whereas the noise level (Lb and $L(E)$b) is negatively correlated. The fact that the pleasantness of the i- scenes is not correlated to global physical features, contrary to pleasantness of ni- scenes has been recently studied [11].
The existence of two perceptual modes involving different types of features, and depending on the nature (in our case hedonic) of the stimuli, is a phenomenon similar to the one observed for the perception of textures (see section 2.1). the brain adapts its way to encode the information (statistic summary for textures, fine description for events) following a previous decision making with regards to the nature of the stimuli (i.e. is it an event or a texture ?). Similarly, features that are active in the pleasantness judgment also depends on a preliminary judgment of the global hedonic nature of the environment (ideal or non ideal).
